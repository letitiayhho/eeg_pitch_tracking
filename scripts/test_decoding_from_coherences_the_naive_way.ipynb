{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "99663cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "from mne_bids import BIDSPath, read_raw_bids\n",
    "from bids import BIDSLayout\n",
    "from util.io.coherence import *\n",
    "from util.io.iter_BIDSPaths import *\n",
    "from mne_connectivity import spectral_connectivity_time, check_indices\n",
    "from scipy.signal import coherence\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mne.decoding import SlidingEstimator, cross_val_multiscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ef46bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB = '31'\n",
    "RUN = '1'\n",
    "TASK = 'pitch'\n",
    "FPATH = '/project2/hcn1/pitch_tracking/data/bids/derivatives/preprocessing/sub-31/sub-31_task-pitch_run-1_res-hi_desc-clean_epo.fif.gz'\n",
    "\n",
    "BIDS_ROOT = '../data/bids'\n",
    "FIGS_ROOT = '../figs'\n",
    "\n",
    "DERIV_ROOT = '../data/bids/derivatives'\n",
    "METHOD = 'coh'\n",
    "FS = 5000\n",
    "RAW_TMIN = -0.2\n",
    "RAW_TMAX = 0.5\n",
    "TMIN = 0\n",
    "TMAX = 0.25\n",
    "N_CHANS = 62\n",
    "CONDS = ['50', '100', '150', '200', '250']\n",
    "FREQS = [50, 100, 150, 200, 250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74e77d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /project2/hcn1/pitch_tracking/data/bids/derivatives/preprocessing/sub-31/sub-31_task-pitch_run-1_res-hi_desc-clean_epo.fif.gz ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     250.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Reading /project2/hcn1/pitch_tracking/data/bids/derivatives/preprocessing/sub-31/sub-31_task-pitch_run-1_res-hi_desc-clean_epo.fif-1.gz ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     250.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "4801 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "# Load epoched data\n",
    "epochs = mne.read_epochs(FPATH, preload = True)\n",
    "events = epochs.events\n",
    "n_epochs = len(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec61b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a different sub for generating stim channels if sub has bad Aux channel\n",
    "STIM_SUB, STIM_RUN = get_stim_sub(SUB, RUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7511f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['100', '150', '200', '250', '50']\n",
      "Not setting metadata\n",
      "6000 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project2/hcn1/pitch_tracking/scripts/util/io/coherence.py:42: RuntimeWarning: The unit for channel(s) Aux1 has changed from NA to V.\n",
      "  raw = read_raw_bids(bids_path, verbose = False)\n",
      "/project2/hcn1/pitch_tracking/scripts/util/io/coherence.py:42: RuntimeWarning: There are channels without locations (n/a) that are not marked as bad: ['leog', 'reog', 'Aux1']\n",
      "  raw = read_raw_bids(bids_path, verbose = False)\n",
      "/project2/hcn1/pitch_tracking/scripts/util/io/coherence.py:42: RuntimeWarning: Not setting position of 1 stim channel found in montage:\n",
      "['Aux1']\n",
      "Consider setting the channel types to be of EEG/sEEG/ECoG/DBS/fNIRS using inst.set_channel_types before calling inst.set_montage, or omit these channels when creating your montage.\n",
      "  raw = read_raw_bids(bids_path, verbose = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 1180 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 1234 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 1216 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 1219 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 1151 events and 3501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "4801 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "# Create epochs from raw data to create simulated stim channels\n",
    "raw_epochs = get_raw_epochs(BIDS_ROOT, STIM_SUB, TASK, STIM_RUN)\n",
    "stim_epochs_array = create_stim_epochs_array(raw_epochs, n_epochs, CONDS)\n",
    "simulated_epochs = create_stim_epochs_object(stim_epochs_array, events, CONDS, FS, RAW_TMIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a314079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop data so both epoch objects have same windowing\n",
    "# epochs is (4801, 62, 1251) which is (epochs, channels, time points)\n",
    "# simulated epochs is (5, 1251) which is (freqs, time points)\n",
    "\n",
    "simulated_epochs = simulated_epochs.crop(tmin = TMIN, tmax = TMAX)\n",
    "epochs = epochs.crop(tmin = TMIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "970d1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only one version of stim signals\n",
    "stim_array = simulated_epochs.get_data()[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8d20d126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target array\n",
    "labels = pd.Series(events[:, 2])\n",
    "y = labels.replace({10001 : 0, 10002 : 1, 10003 : 2, 10004 : 3, 10005 : 4})\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058cebce",
   "metadata": {},
   "source": [
    "### Keep coherence values at all stim freqs for each stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b7ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What shape does it need to be for decoding?? Keep this in mind!\n",
    "# Shape of Zxx for stft is n_epochs, n_freqs*n_chans, n_windows\n",
    "# Shape of Zxx in general is a trials, features, time array\n",
    "# Shape of Zxx in this case is n_epochs, n_chans, n_stim, n_freqs\n",
    "\n",
    "# Compute coherence\n",
    "epoch_array = epochs.get_data()\n",
    "n_epochs = np.shape(epoch_array)[0]\n",
    "n_chans = np.shape(epoch_array)[1]\n",
    "n_stim = 5\n",
    "n_freqs = 5\n",
    "\n",
    "X = np.zeros((n_epochs, n_chans, n_stim, n_freqs))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_X = []\n",
    "    for channel in range(n_chans):\n",
    "        current_epoch = epoch_array[epoch, channel, :]\n",
    "        for stim in range(n_stim):\n",
    "            current_freq = stim_array[stim, :]\n",
    "            \n",
    "            # compute coherence\n",
    "            f, Cxy = coherence(current_epoch, current_freq, FS)\n",
    "            \n",
    "            # get coherences for condition frequencies only\n",
    "            Cxy = extract_coherence_for_condition_frequencies(FREQS, f, Cxy) \n",
    "            \n",
    "            # add to array\n",
    "            X[epoch, channel, stim, :] = Cxy\n",
    "\n",
    "#             break\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0b1b2b",
   "metadata": {},
   "source": [
    "#### Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b1858960",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m n_stimuli \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      2\u001b[0m metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m clf \u001b[38;5;241m=\u001b[39m make_pipeline(\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mStandardScaler\u001b[49m(),\n\u001b[1;32m      6\u001b[0m     LogisticRegression(solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating sliding estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m time_decod \u001b[38;5;241m=\u001b[39m SlidingEstimator(clf)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "n_stimuli = 5\n",
    "metric = 'accuracy'\n",
    "\n",
    "clf = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(solver = 'liblinear')\n",
    ")\n",
    "\n",
    "print(\"Creating sliding estimators\")\n",
    "time_decod = SlidingEstimator(clf)\n",
    "\n",
    "print(\"Fit estimators\")\n",
    "scores = cross_val_multiscore(\n",
    "    time_decod,\n",
    "    X, # a trials x features x time array\n",
    "    y, # an (n_trials,) array of integer condition labels\n",
    "    cv = 5, # use stratified 5-fold cross-validation\n",
    "    n_jobs = -1, # use all available CPU cores\n",
    ")\n",
    "scores = np.mean(scores, axis = 0) # average across cv splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479ee7c4",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5624399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(len(scores)), scores, label = 'score')\n",
    "ax.axhline(1/n_stimuli, color = 'k', linestyle = '--', label = 'chance')\n",
    "ax.set_xlabel('Times')\n",
    "ax.set_ylabel(metric)  # Area Under the Curve\n",
    "ax.legend()\n",
    "ax.set_title('Sensor space decoding')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc60eed4",
   "metadata": {},
   "source": [
    "### Keep only coherence values at the frequency of each stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "38284360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What shape does it need to be for decoding?? Keep this in mind!\n",
    "# Shape of Zxx for stft is n_epochs, n_freqs*n_chans, n_windows\n",
    "# Shape of Zxx in general is a trials, features, time array\n",
    "# Shape of Zxx in this case is n_epochs, n_chans, n_stim, n_freqs\n",
    "\n",
    "# Compute coherence\n",
    "epoch_array = epochs.get_data()\n",
    "n_epochs = np.shape(epoch_array)[0]\n",
    "n_chans = np.shape(epoch_array)[1]\n",
    "n_stim = 5\n",
    "# n_freqs = 5\n",
    "\n",
    "X = np.zeros((3, n_chans, n_stim))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_X = []\n",
    "    for channel in range(n_chans):\n",
    "        current_epoch = epoch_array[epoch, channel, :]\n",
    "        for stim in range(n_stim):\n",
    "            current_freq = stim_array[stim, :]\n",
    "            \n",
    "            # compute coherence\n",
    "            f, Cxy = coherence(current_epoch, current_freq, FS)\n",
    "            \n",
    "            # get coherences for condition frequencies only\n",
    "            Cxy = extract_coherence_at_condition_frequencies(FREQS[stim], f, Cxy) \n",
    "            \n",
    "            # add to array\n",
    "            X[epoch, channel, stim] = Cxy\n",
    "\n",
    "            break\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13bd9be",
   "metadata": {},
   "source": [
    "#### Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb78bb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.17382976, 0.05041848, 0.08968121, 0.03331252, 0.00431147],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_stimuli = 5\n",
    "metric = 'accuracy'\n",
    "\n",
    "clf = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(solver = 'liblinear')\n",
    ")\n",
    "\n",
    "print(\"Creating sliding estimators\")\n",
    "time_decod = SlidingEstimator(clf)\n",
    "\n",
    "print(\"Fit estimators\")\n",
    "scores = cross_val_multiscore(\n",
    "    time_decod,\n",
    "    X, # a trials x features x time array\n",
    "    y, # an (n_trials,) array of integer condition labels\n",
    "    cv = 5, # use stratified 5-fold cross-validation\n",
    "    n_jobs = -1, # use all available CPU cores\n",
    ")\n",
    "scores = np.mean(scores, axis = 0) # average across cv splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a4b652",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f60759",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(len(scores)), scores, label = 'score')\n",
    "ax.axhline(1/n_stimuli, color = 'k', linestyle = '--', label = 'chance')\n",
    "ax.set_xlabel('Times')\n",
    "ax.set_ylabel(metric)  # Area Under the Curve\n",
    "ax.legend()\n",
    "ax.set_title('Sensor space decoding')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
